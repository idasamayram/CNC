{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-17T16:53:47.375223Z",
     "start_time": "2025-02-17T16:53:46.841161Z"
    }
   },
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom  # Alternative to cv2.resize\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:04:58.935346Z",
     "start_time": "2025-02-17T17:04:58.925579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VibrationDatasetWithMetadata(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.file_paths = []\n",
    "        self.labels = []\n",
    "        self.metadata = []\n",
    "\n",
    "        # Define machine and operation mappings\n",
    "        self.machine_mapping = {\"M01\": 0, \"M02\": 1, \"M03\": 2}\n",
    "        self.operation_mapping = {\n",
    "            \"OP01\": [0, 250, 100],  # Step Drill\n",
    "            \"OP02\": [1, 200, 50],   # Drill\n",
    "            \"OP04\": [2, 250, 100],  # Step Drill\n",
    "            \"OP07\": [3, 200, 50],   # Step Drill\n",
    "            \"OP10\": [4, 250, 50]    # Step Drill\n",
    "        }\n",
    "\n",
    "        for label, label_idx in zip([\"good\", \"bad\"], [0, 1]):  # 0 = good, 1 = bad\n",
    "            folder = Path(data_dir) / label\n",
    "            for file_name in os.listdir(folder):\n",
    "                if file_name.endswith(\".h5\"):\n",
    "                    self.file_paths.append(os.path.join(folder, file_name))\n",
    "                    self.labels.append(label_idx)\n",
    "\n",
    "                    # Extract metadata from filename\n",
    "                    parts = file_name.split(\"_\")\n",
    "                    machine = parts[0]  # \"M01\"\n",
    "                    operation = parts[3]  # \"OP01\"\n",
    "\n",
    "                    machine_encoded = self.machine_mapping.get(machine, -1)\n",
    "                    op_metadata = self.operation_mapping.get(operation, [-1, -1, -1])\n",
    "\n",
    "                    # Final metadata: [Machine ID, Operation ID, Spindle Speed, Feed Rate]\n",
    "                    self.metadata.append([machine_encoded] + op_metadata)\n",
    "\n",
    "        self.metadata = np.array(self.metadata)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        with h5py.File(file_path, \"r\") as f:\n",
    "            data = f[\"vibration_data\"][:]  # Shape (10000, 3)\n",
    "\n",
    "        data = np.transpose(data, (1, 0))  # Change to (3, 10000) for CNN\n",
    "        label = self.labels[idx]\n",
    "        metadata = torch.tensor(self.metadata[idx], dtype=torch.float32)\n",
    "\n",
    "        return torch.tensor(data, dtype=torch.float32), metadata, torch.tensor(label, dtype=torch.long)\n"
   ],
   "id": "5ec8d57a370bde53",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:05:11.229362Z",
     "start_time": "2025-02-17T17:05:11.205264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNN1DWithMetadata(nn.Module):\n",
    "    def __init__(self, num_metadata_features=4):  # 4 metadata values now\n",
    "        super(CNN1DWithMetadata, self).__init__()\n",
    "\n",
    "        # CNN branch (for vibration signals)\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=16, kernel_size=7, stride=1, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.cnn_fc = nn.Linear(64 * 1250, 128)  # CNN feature output\n",
    "\n",
    "        # Metadata branch (small MLP)\n",
    "        self.metadata_fc1 = nn.Linear(num_metadata_features, 16)\n",
    "        self.metadata_fc2 = nn.Linear(16, 16)\n",
    "\n",
    "        # Final classification layer (combined CNN + metadata features)\n",
    "        self.final_fc1 = nn.Linear(128 + 16, 64)\n",
    "        self.final_fc2 = nn.Linear(64, 2)  # Binary classification (good/bad)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, metadata):\n",
    "        # CNN branch\n",
    "        x = self.pool1(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(self.relu(self.bn3(self.conv3(x))))\n",
    "\n",
    "        x = x.view(x.shape[0], -1)  # Flatten CNN output\n",
    "        x = self.relu(self.cnn_fc(x))\n",
    "\n",
    "        # Metadata branch\n",
    "        metadata = self.relu(self.metadata_fc1(metadata))\n",
    "        metadata = self.relu(self.metadata_fc2(metadata))\n",
    "\n",
    "        # Concatenate CNN and metadata features\n",
    "        combined = torch.cat((x, metadata), dim=1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        combined = self.relu(self.final_fc1(combined))\n",
    "        combined = self.dropout(combined)\n",
    "        combined = self.final_fc2(combined)\n",
    "\n",
    "        return combined\n"
   ],
   "id": "a1b7e363ef4dac6",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T16:21:49.605314Z",
     "start_time": "2025-02-13T16:21:49.599081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------\n",
    "# 3️⃣ Training, Validation & Testing Functions\n",
    "# ------------------------\n",
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    for inputs, metadata, labels in train_loader:\n",
    "        inputs, metadata, labels = inputs.to(device), metadata.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, metadata)  # Forward pass\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(train_loader), accuracy\n",
    "\n",
    "\n"
   ],
   "id": "80b0461b01ffe6ef",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T16:21:50.315129Z",
     "start_time": "2025-02-13T16:21:50.305932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, metadata, labels in val_loader:\n",
    "            inputs, metadata, labels = inputs.to(device), metadata.to(device), labels.to(device)\n",
    "            outputs = model(inputs, metadata)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(val_loader), accuracy\n",
    "\n",
    "\n"
   ],
   "id": "f9aba127808c0346",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T16:21:52.736136Z",
     "start_time": "2025-02-13T16:21:52.732075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, metadata, labels in test_loader:\n",
    "            inputs, metadata, labels = inputs.to(device), metadata.to(device), labels.to(device)\n",
    "            outputs = model(inputs, metadata)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = (np.array(all_preds) == np.array(all_labels)).mean()\n",
    "    return accuracy"
   ],
   "id": "8d250ce8a502c2ad",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:05:49.846850Z",
     "start_time": "2025-02-17T17:05:49.836808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------\n",
    "# 5️⃣ Full Training & Evaluation Function\n",
    "# ------------------------\n",
    "def train_and_evaluate(train_loader, val_loader, test_loader, epochs=20, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize the model with metadata processing\n",
    "    model = CNN1DWithMetadata(num_metadata_features=4).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} - \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    print(\"✅ Training and validation complete!\")\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_accuracy = test_model(model, test_loader, device)\n",
    "    print(f\"🔥 Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    return model\n"
   ],
   "id": "f04d39d46399e637",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:06:10.354077Z",
     "start_time": "2025-02-17T17:05:52.528424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "data_directory = \"../data/final/Selected_data_windowed_grouped_normalized\"\n",
    "dataset = VibrationDatasetWithMetadata(data_directory)\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Train & evaluate model\n",
    "model = train_and_evaluate(train_loader, val_loader, test_loader, epochs=20, lr=0.001)\n",
    "\n",
    "\n"
   ],
   "id": "41db44d8c8d61e33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Train Loss: 5.1393, Train Acc: 0.5583 - Val Loss: 0.8660, Val Acc: 0.7282\n",
      "Epoch [2/20] - Train Loss: 1.4133, Train Acc: 0.7542 - Val Loss: 0.3240, Val Acc: 0.8641\n",
      "Epoch [3/20] - Train Loss: 0.3573, Train Acc: 0.8521 - Val Loss: 0.2265, Val Acc: 0.9223\n",
      "Epoch [4/20] - Train Loss: 0.2546, Train Acc: 0.8917 - Val Loss: 0.1704, Val Acc: 0.9029\n",
      "Epoch [5/20] - Train Loss: 0.2067, Train Acc: 0.9187 - Val Loss: 0.1655, Val Acc: 0.9126\n",
      "Epoch [6/20] - Train Loss: 0.1552, Train Acc: 0.9375 - Val Loss: 0.2745, Val Acc: 0.9029\n",
      "Epoch [7/20] - Train Loss: 0.0938, Train Acc: 0.9625 - Val Loss: 0.1811, Val Acc: 0.8835\n",
      "Epoch [8/20] - Train Loss: 0.0953, Train Acc: 0.9625 - Val Loss: 0.1685, Val Acc: 0.9126\n",
      "Epoch [9/20] - Train Loss: 0.0616, Train Acc: 0.9750 - Val Loss: 0.2102, Val Acc: 0.9126\n",
      "Epoch [10/20] - Train Loss: 0.0566, Train Acc: 0.9854 - Val Loss: 0.1772, Val Acc: 0.9126\n",
      "Epoch [11/20] - Train Loss: 0.0529, Train Acc: 0.9854 - Val Loss: 0.3570, Val Acc: 0.8835\n",
      "Epoch [12/20] - Train Loss: 0.0425, Train Acc: 0.9917 - Val Loss: 0.1889, Val Acc: 0.9417\n",
      "Epoch [13/20] - Train Loss: 0.0206, Train Acc: 0.9958 - Val Loss: 0.2005, Val Acc: 0.9417\n",
      "Epoch [14/20] - Train Loss: 0.0135, Train Acc: 0.9979 - Val Loss: 0.2095, Val Acc: 0.9320\n",
      "Epoch [15/20] - Train Loss: 0.0260, Train Acc: 0.9938 - Val Loss: 0.1937, Val Acc: 0.9417\n",
      "Epoch [16/20] - Train Loss: 0.0496, Train Acc: 0.9771 - Val Loss: 0.1759, Val Acc: 0.9417\n",
      "Epoch [17/20] - Train Loss: 0.0212, Train Acc: 0.9938 - Val Loss: 0.2703, Val Acc: 0.9320\n",
      "Epoch [18/20] - Train Loss: 0.0118, Train Acc: 0.9938 - Val Loss: 0.1880, Val Acc: 0.9223\n",
      "Epoch [19/20] - Train Loss: 0.0171, Train Acc: 0.9938 - Val Loss: 0.2073, Val Acc: 0.9320\n",
      "Epoch [20/20] - Train Loss: 0.0181, Train Acc: 0.9917 - Val Loss: 0.1722, Val Acc: 0.9417\n",
      "✅ Training and validation complete!\n",
      "🔥 Final Test Accuracy: 0.9712\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:06:16.332055Z",
     "start_time": "2025-02-17T17:06:16.231746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"cnn1d_with_metadata.ckpt\")\n",
    "print(\"✅ Model saved to cnn1d_with_metadata.ckpt\")"
   ],
   "id": "e046c2508cccf0e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to cnn1d_with_metadata.ckpt\n"
     ]
    }
   ],
   "execution_count": 47
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
